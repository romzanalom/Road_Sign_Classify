{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1D5abtJVfXZDNWp5SvbT-YqNjnRNJP1jp","authorship_tag":"ABX9TyMRP1K9e+NTs8YIP58SQoPi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"yWbKk31vrroL","executionInfo":{"status":"ok","timestamp":1691915147245,"user_tz":-360,"elapsed":1351,"user":{"displayName":"Md.Romzan Alom","userId":"16239610101153521411"}}},"outputs":[],"source":["import os\n","import pandas as pd\n","from PIL import Image\n","\n","# Specify the path to your image dataset folder\n","dataset_folder = '/content/drive/MyDrive/line road images'\n","\n","# Create empty lists to store image paths and labels\n","image_paths = []\n","labels = []\n","\n","# Loop through the dataset folder and retrieve image paths and labels\n","for class_label in os.listdir(dataset_folder):\n","    class_folder = os.path.join(dataset_folder, class_label)\n","    if os.path.isdir(class_folder):\n","        for image_file in os.listdir(class_folder):\n","            image_path = os.path.join(class_folder, image_file)\n","            image_paths.append(image_path)\n","            labels.append(class_label)\n","\n","# Create a DataFrame with image paths and labels\n","data = {'Image_Path': image_paths, 'Label': labels}\n","df = pd.DataFrame(data)\n","\n","# Save the DataFrame as a CSV file\n","df.to_csv('image_dataset.csv', index=False)"]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from keras.optimizers import Adam\n","\n","# Specify the desired width and height for the images\n","image_width = 200\n","image_height = 200\n","\n","# Load the dataset from a CSV file\n","dataset = pd.read_csv('/content/image_dataset.csv')\n","\n","# Load and preprocess the image data\n","X = []\n","y = []\n","for index, row in dataset.iterrows():\n","    image_path = row['Image_Path']\n","    if os.path.isdir(image_path):\n","        print(f\"Skipping directory: {image_path}\")\n","        continue\n","    try:\n","        image = Image.open(image_path)\n","        image = image.resize((image_width, image_height))  # Resize the image to a consistent size\n","        image = np.array(image) / 255.0  # Normalize pixel values to [0, 1]\n","    except Exception as e:\n","        print(f\"Error loading image: {image_path}. Skipping...\")\n","        print(f\"Error message: {str(e)}\")\n","        continue\n","    if image.shape != (image_width, image_height, 3):\n","        print(f\"Inconsistent shape for image: {image_path}. Skipping...\")\n","        continue\n","    X.append(image)\n","    y.append(row['Label'])\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","# Encode class labels to integers\n","label_encoder = LabelEncoder()\n","y = label_encoder.fit_transform(y)\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Convert class labels to one-hot encoded vectors\n","num_classes = len(np.unique(y))\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","# Create the CNN model\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(image_width, image_height, 3)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))  # Apply dropout regularization\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","# Compile the model\n","model.compile(optimizer=Adam(learning_rate=0.001),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ub_DQQZjsSV9","executionInfo":{"status":"ok","timestamp":1691860037025,"user_tz":-360,"elapsed":22918,"user":{"displayName":"Md.Romzan Alom","userId":"16239610101153521411"}},"outputId":"666ce05e-4ef5-49ce-94db-db517f473261"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Skipping directory: /content/drive/MyDrive/line road images/Broken yellow line road images/.ipynb_checkpoints\n","Skipping directory: /content/drive/MyDrive/line road images/Single yellow line road images/.ipynb_checkpoints\n"]}]},{"cell_type":"code","source":["# Print the model summary\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RdxY3SJ3twKz","executionInfo":{"status":"ok","timestamp":1691860047659,"user_tz":-360,"elapsed":582,"user":{"displayName":"Md.Romzan Alom","userId":"16239610101153521411"}},"outputId":"c8db78e1-b481-4029-d4a8-23f1017f1f0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 198, 198, 32)      896       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 99, 99, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 97, 97, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 48, 48, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 147456)            0         \n","                                                                 \n"," dense (Dense)               (None, 128)               18874496  \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 6)                 774       \n","                                                                 \n","=================================================================\n","Total params: 18,894,662\n","Trainable params: 18,894,662\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["\n","# Train the model\n","model.fit(X_train, y_train,\n","          batch_size=32,\n","          epochs=10,\n","          validation_data=(X_test, y_test))\n","\n","# Evaluate the model\n","score = model.evaluate(X_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ij47FnE0trP2","executionInfo":{"status":"ok","timestamp":1691860102425,"user_tz":-360,"elapsed":42908,"user":{"displayName":"Md.Romzan Alom","userId":"16239610101153521411"}},"outputId":"d6d075c4-f467-4829-ea92-f76016266c27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1/1 [==============================] - 4s 4s/step - loss: 1.8196 - accuracy: 0.0938 - val_loss: 12.5626 - val_accuracy: 0.1250\n","Epoch 2/10\n","1/1 [==============================] - 4s 4s/step - loss: 11.0291 - accuracy: 0.1875 - val_loss: 11.6775 - val_accuracy: 0.1250\n","Epoch 3/10\n","1/1 [==============================] - 2s 2s/step - loss: 8.5690 - accuracy: 0.2812 - val_loss: 10.6777 - val_accuracy: 0.1250\n","Epoch 4/10\n","1/1 [==============================] - 2s 2s/step - loss: 8.2277 - accuracy: 0.2188 - val_loss: 4.6271 - val_accuracy: 0.1250\n","Epoch 5/10\n","1/1 [==============================] - 2s 2s/step - loss: 4.9202 - accuracy: 0.1875 - val_loss: 2.5777 - val_accuracy: 0.1250\n","Epoch 6/10\n","1/1 [==============================] - 2s 2s/step - loss: 2.7987 - accuracy: 0.2500 - val_loss: 2.4996 - val_accuracy: 0.1250\n","Epoch 7/10\n","1/1 [==============================] - 4s 4s/step - loss: 2.0539 - accuracy: 0.3438 - val_loss: 1.5530 - val_accuracy: 0.2500\n","Epoch 8/10\n","1/1 [==============================] - 3s 3s/step - loss: 1.3598 - accuracy: 0.5625 - val_loss: 1.6630 - val_accuracy: 0.2500\n","Epoch 9/10\n","1/1 [==============================] - 2s 2s/step - loss: 1.1218 - accuracy: 0.6250 - val_loss: 1.9624 - val_accuracy: 0.1250\n","Epoch 10/10\n","1/1 [==============================] - 2s 2s/step - loss: 1.0487 - accuracy: 0.8125 - val_loss: 1.9990 - val_accuracy: 0.2500\n","Test loss: 1.9989540576934814\n","Test accuracy: 0.25\n"]}]},{"cell_type":"code","source":["from PIL import Image\n","import numpy as np\n","\n","# Load and preprocess a new image\n","image_path = '/content/img1.jpeg'  # Replace with the path to your new image\n","image_width = 200\n","image_height = 200\n","\n","image = Image.open(image_path)\n","image = image.resize((image_width, image_height))\n","image = np.array(image) / 255.0\n","image = np.expand_dims(image, axis=0)  # Add an extra dimension to match the input shape of the model\n","\n","# Make predictions using your trained model\n","predictions = model.predict(image)\n","predicted_class = np.argmax(predictions)\n","\n","# Convert the predicted class index back to the original label\n","predicted_label = label_encoder.inverse_transform([predicted_class])[0]\n","\n","print('Predicted class:', predicted_class)\n","print('Predicted label:', predicted_label)\n","\n","#meaning road sign\n","print(\"The meaning of\", predicted_label ,\"Lane:\")\n","if predicted_class == 0:\n","    print(\"You can cross the line to change lanes if it is safe to do so.\")\n","elif predicted_class == 1:\n","    print(\"You can pass a slower moving vehicle on the left side if it is safe to do so.\")\n","elif predicted_class == 2:\n","    print(\"You cannot cross the line to change lanes or pass a slower moving vehicle. This is because double yellow lines indicate that there is a no-passing zone.\")\n","elif predicted_class == 3:\n","    print(\"You cannot cross the line to change lanes or pass a slower moving vehicle. This is because double white lines indicate that there is a no-passing zone.\")\n","elif predicted_class == 4:\n","    print(\"Indicates that you cannot cross the line to change lanes.\")\n","elif predicted_class == 5:\n","    print(\"Indicates that you cannot pass a slower moving vehicle on the left side.\")\n","else:\n","    print(\"Sorry, this sign is not added.\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cOy2zFIUsZ0g","executionInfo":{"status":"ok","timestamp":1691862072697,"user_tz":-360,"elapsed":998,"user":{"displayName":"Md.Romzan Alom","userId":"16239610101153521411"}},"outputId":"1d50b803-35d4-4263-98ba-0b23f8c71bf5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 57ms/step\n","Predicted class: 0\n","Predicted label: Broken White line road images\n","The meaning of Broken White line road images Lane:\n","You can cross the line to change lanes if it is safe to do so.\n"]}]}]}